{"cells":[{"cell_type":"markdown","metadata":{"id":"veP8EzgbdBXW"},"source":["# Batch Size: Batch size refers to the number of data points considered to calculate the loss value or update weights"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4816,"status":"ok","timestamp":1684393075028,"user":{"displayName":"Sahil Sheikh","userId":"07547610742251332939"},"user_tz":-330},"id":"czzdEJW6dDLJ"},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","import torch\n","import torch.nn as nn"]},{"cell_type":"markdown","metadata":{"id":"fCp2eqAzdRh9"},"source":["# Define the same dataset as in the previous lessons"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1163,"status":"ok","timestamp":1684393106599,"user":{"displayName":"Sahil Sheikh","userId":"07547610742251332939"},"user_tz":-330},"id":"odDKbk1VdKH9"},"outputs":[],"source":["x = [[1,2],[3,4],[5,6],[7,8]]\n","y = [[3],[7],[11],[15]]"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1684393112805,"user":{"displayName":"Sahil Sheikh","userId":"07547610742251332939"},"user_tz":-330},"id":"xA9vhkghdOwk"},"outputs":[],"source":["X = torch.tensor(x).float()\n","Y = torch.tensor(y).float()"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1684393113416,"user":{"displayName":"Sahil Sheikh","userId":"07547610742251332939"},"user_tz":-330},"id":"0huGxSDEcyFY"},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","X = X.to(device)\n","Y = Y.to(device)"]},{"cell_type":"markdown","metadata":{"id":"BQGJO8m-eA48"},"source":["In the MyDataset class, we hold the necessary details for retrieving individual data points, allowing us to group them into batches (using DataLoader) and process them together in a single forward and back-propagation step to update the weights."]},{"cell_type":"markdown","metadata":{"id":"_y1hWLKueWrj"},"source":["# Theser are 3 main things you need to remember\n","## 1) Inherit from Dataset class and implement __init__ method\n","## 2) Implement __getitem__ method (Whatever this method returns is what we get when we create a dataloader)\n","## 3) Implement __len__ method\n","## These 3 functions are a necessity, there is also a collate_fn which I would cover in the future lessons"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":379,"status":"ok","timestamp":1684393119492,"user":{"displayName":"Sahil Sheikh","userId":"07547610742251332939"},"user_tz":-330},"id":"LjIe9yMgeI2k"},"outputs":[],"source":["class MyDataset(Dataset):\n","  def __init__(self,x,y):\n","    self.x = torch.tensor(x).float().to(device)\n","    self.y = torch.tensor(y).float().to(device)\n","  def __len__(self):\n","    return len(self.x)\n","  def __getitem__(self,ix):\n","    return self.x[ix], self.y[ix]"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1684393121069,"user":{"displayName":"Sahil Sheikh","userId":"07547610742251332939"},"user_tz":-330},"id":"f8sbc1SteBW9"},"outputs":[],"source":["ds = MyDataset(x,y)"]},{"cell_type":"markdown","metadata":{"id":"95PsnktTf6Cb"},"source":["# Dataloader object is used to load data from a dataset and return it in the form of mini-batches. It provides an iterable over the dataset, with support for multi-process data loading and customizable data transformation."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":621,"status":"ok","timestamp":1684393122340,"user":{"displayName":"Sahil Sheikh","userId":"07547610742251332939"},"user_tz":-330},"id":"US8B13-0f0PH"},"outputs":[],"source":["# Notice Batch size\n","dl = DataLoader(ds, batch_size=2, shuffle=True)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682360545175,"user":{"displayName":"Sahil Sheikh","userId":"07547610742251332939"},"user_tz":-330},"id":"1xhaoA1Jf5Bf","outputId":"dc0af16b-11a0-4fa7-d64e-e892a3486f2d"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[3., 4.],\n","        [7., 8.]], device='cuda:0') tensor([[ 7.],\n","        [15.]], device='cuda:0')\n","tensor([[1., 2.],\n","        [5., 6.]], device='cuda:0') tensor([[ 3.],\n","        [11.]], device='cuda:0')\n"]}],"source":["# To load the data we loop through it\n","for x,y in dl:\n","  print(x,y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AFFAMefsgKiT"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"-tee4vhKgi4Z"},"source":["# Using the DataLoader object in the training code"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1684393134122,"user":{"displayName":"Sahil Sheikh","userId":"07547610742251332939"},"user_tz":-330},"id":"4B2snffDgz1C"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.optim import SGD"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NEZyuQz7qx8E"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1684393135306,"user":{"displayName":"Sahil Sheikh","userId":"07547610742251332939"},"user_tz":-330},"id":"zluQiZ0Xgl9q"},"outputs":[],"source":["class MyNeuralNet(nn.Module):\n","  def __init__(self):  \n","    # When we call the super.__init__() method we ensure we are inhertiting   \n","    super().__init__()\n","    self.layer1 = nn.Linear(2,8) # A linear layer\n","    self.activation = nn.ReLU() # activation function\n","    self.layer2 =  nn.Linear(8,1)\n","\n","  # When we pass something through the model object, it calls the forward function \n","  def forward(self,x):\n","    x = self.layer1(x)\n","    x = self.activation(x)\n","    x = self.layer2(x)\n","    return x"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":393,"status":"ok","timestamp":1684393146765,"user":{"displayName":"Sahil Sheikh","userId":"07547610742251332939"},"user_tz":-330},"id":"UpYP8hHYgrxN"},"outputs":[],"source":["model = MyNeuralNet()\n","loss_func = nn.MSELoss()\n","opt = SGD(model.parameters(), lr = 0.001)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":437,"status":"ok","timestamp":1684393150803,"user":{"displayName":"Sahil Sheikh","userId":"07547610742251332939"},"user_tz":-330},"id":"JQYdZSYIgvuL"},"outputs":[{"ename":"RuntimeError","evalue":"Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# Setting gradients to zero before every epoch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m x1, y1 \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m----> 6\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m loss_func(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m,y1)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#  the gradients of the loss function with respect to all the trainable parameters of the network are computed and stored in the grad attribute of the corresponding tensors.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m loss_value\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m~/lamia-bootcamp/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/lamia-bootcamp/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[10], line 11\u001b[0m, in \u001b[0;36mMyNeuralNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m---> 11\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(x)\n\u001b[1;32m     13\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n","File \u001b[0;32m~/lamia-bootcamp/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/lamia-bootcamp/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/lamia-bootcamp/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"]}],"source":["losses = []\n","for _ in range(50): #Running for 50 epochs\n","  for data in dl:\n","    opt.zero_grad() # Setting gradients to zero before every epoch\n","    x1, y1 = data\n","    loss_value = loss_func(model(x1),y1)\n","    #  the gradients of the loss function with respect to all the trainable parameters of the network are computed and stored in the grad attribute of the corresponding tensors.\n","    loss_value.backward()\n","\n","    # opt.step() is to update the weights and biases of the neural network using the computed gradients and the chosen optimization algorithm\n","    opt.step() \n","    losses.append(loss_value.detach().numpy())"]},{"cell_type":"markdown","metadata":{"id":"vIRtHheFhH0Q"},"source":["# By using a dataloader object we are able to train the model much faster, as batch processing is taking place"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bIOKenkUhOlC"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t73P0_m3hEoX"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"daQZ9stUdZpJ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YSHEpbJ3c08V"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uYfDvZlDc05m"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_TIkXh7vc03Q"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VKAku47rc002"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mF8Oyxwlc0yl"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bx_cfO6Lc0wF"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hRm_o5qNc0tt"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3B6rCeopc0rd"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DyvwEdXnc0pF"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U6BtH2bFc0m1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NwfMyo3Oc0kP"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CXjUZ-7Oc0h9"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Y1KbByQc0ft"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PGT6ZLY2c0dV"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNzDFW7jz1KD4XqjRYt0+a7","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}
